version: '3'
services:
  mongo:
    image: mongo
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    ports:
      - 27017:27017
  zookeeper:
    image: 'bitnami/zookeeper:latest'
    ports:
      - '2181:2181'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
  kafka:
    image: 'bitnami/kafka:latest'
    ports:
      - '9092:9092'
      - '9093:9093'
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=CLIENT://:9092,EXTERNAL://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka:9092,EXTERNAL://localhost:9093
      - KAFKA_INTER_BROKER_LISTENER_NAME=CLIENT
    depends_on:
      - zookeeper
#  event-generator:
#    build:
#      dockerfile: ./docker/Dockerfile
#      context: ./
#    volumes:
#      - ./:/usr/src/app
#    stdin_open: true
  event-receiver:
    build:
      dockerfile: ./docker/Dockerfile
      context: ./
    volumes:
      - ./:/usr/src/app
    command:
      - "python"
      - "./app/EventReceiver.py"
    environment:
      PYTHONPATH: "/usr/src/app/"
  web-service:
    build:
      dockerfile: ./docker/Dockerfile
      context: ./
    ports:
      - '8080:8080'
    volumes:
      - ./:/usr/src/app
    command:
      - "python"
      - "./app/WebService.py"
    environment:
      PYTHONPATH: "/usr/src/app/"
  spark:
    build:
      dockerfile: ./docker/Dockerfile
      context: ./
    volumes:
      - ./:/usr/src/app
    command:
      - "/usr/local/lib/python3.10/site-packages/pyspark/bin/spark-submit"
      - "--packages"
      - "org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0"
      - "./app/Spark.py"
    environment:
      PYTHONPATH: "/usr/src/app/"
